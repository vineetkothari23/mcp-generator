"""
End-to-End Integration Tests for OpenAPIEnhancedGenerator

These tests validate the complete flow using REAL tools:
1. OpenAPI specification â†’ OpenAPIClientGenerator â†’ client code (using real openapi-generator-cli)
2. Client analysis â†’ MCPToolMapper â†’ enhanced MCPProjectConfig
3. Enhanced config â†’ MCPGenerator â†’ complete MCP project
4. Generated project execution and test validation

These are TRUE integration tests that require openapi-generator-cli to be installed.
"""

import pytest
import tempfile
import subprocess
import sys
import json
import yaml
from pathlib import Path

from mcp_cli.generators import OpenAPIEnhancedGenerator, GenerationResult
from mcp_cli.config import MCPProjectConfig


# Test fixtures for OpenAPI specifications
@pytest.fixture
def petstore_openapi_spec():
    """Simple Pet Store OpenAPI specification for testing"""
    return {
        "openapi": "3.0.0",
        "info": {
            "title": "Pet Store API",
            "description": "A simple pet store API for testing",
            "version": "1.0.0"
        },
        "servers": [
            {"url": "https://api.petstore.example.com"}
        ],
        "paths": {
            "/pets": {
                "get": {
                    "operationId": "listPets",
                    "summary": "List all pets",
                    "description": "Returns a list of pets",
                    "parameters": [
                        {
                            "name": "limit",
                            "in": "query",
                            "description": "How many items to return at one time",
                            "required": False,
                            "schema": {
                                "type": "integer",
                                "format": "int32"
                            }
                        }
                    ],
                    "responses": {
                        "200": {
                            "description": "A paged array of pets",
                            "content": {
                                "application/json": {
                                    "schema": {
                                        "$ref": "#/components/schemas/Pets"
                                    }
                                }
                            }
                        }
                    }
                },
                "post": {
                    "operationId": "createPet",
                    "summary": "Create a pet",
                    "description": "Create a new pet",
                    "requestBody": {
                        "content": {
                            "application/json": {
                                "schema": {
                                    "$ref": "#/components/schemas/Pet"
                                }
                            }
                        }
                    },
                    "responses": {
                        "201": {
                            "description": "Pet created"
                        }
                    }
                }
            },
            "/pets/{petId}": {
                "get": {
                    "operationId": "getPetById",
                    "summary": "Info for a specific pet",
                    "parameters": [
                        {
                            "name": "petId",
                            "in": "path",
                            "required": True,
                            "description": "The id of the pet to retrieve",
                            "schema": {
                                "type": "string"
                            }
                        }
                    ],
                    "responses": {
                        "200": {
                            "description": "Expected response to a valid request",
                            "content": {
                                "application/json": {
                                    "schema": {
                                        "$ref": "#/components/schemas/Pet"
                                    }
                                }
                            }
                        }
                    }
                }
            }
        },
        "components": {
            "schemas": {
                "Pet": {
                    "type": "object",
                    "required": ["id", "name"],
                    "properties": {
                        "id": {
                            "type": "integer",
                            "format": "int64"
                        },
                        "name": {
                            "type": "string"
                        },
                        "tag": {
                            "type": "string"
                        }
                    }
                },
                "Pets": {
                    "type": "array",
                    "items": {
                        "$ref": "#/components/schemas/Pet"
                    }
                }
            }
        }
    }


@pytest.fixture
def simple_openapi_spec():
    """Very simple OpenAPI spec for quick testing"""
    return {
        "openapi": "3.0.0",
        "info": {
            "title": "Simple API",
            "description": "A minimal API for testing",
            "version": "1.0.0"
        },
        "servers": [
            {"url": "https://api.simple.example.com"}
        ],
        "paths": {
            "/items": {
                "get": {
                    "operationId": "getItems",
                    "summary": "Get all items",
                    "responses": {
                        "200": {
                            "description": "List of items",
                            "content": {
                                "application/json": {
                                    "schema": {
                                        "type": "array",
                                        "items": {
                                            "$ref": "#/components/schemas/Item"
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        },
        "components": {
            "schemas": {
                "Item": {
                    "type": "object",
                    "properties": {
                        "id": {"type": "integer"},
                        "name": {"type": "string"}
                    }
                }
            }
        }
    }


@pytest.fixture
def integration_config():
    """Configuration for integration testing"""
    return MCPProjectConfig(
        project_name="test-mcp-server",
        service_name="test_service",
        description="Integration Test MCP Server",
        author="Integration Test Suite",
        version="1.0.0",
        python_version="3.11",
        test_framework="pytest",
        include_docker=False,  # Skip Docker for faster testing
        include_ci=False
    )


# Skip tests if openapi-generator-cli is not available
def check_openapi_generator_available():
    """Check if openapi-generator-cli is available"""
    try:
        result = subprocess.run(
            ['openapi-generator-cli', 'version'],
            capture_output=True,
            text=True,
            timeout=10,
            shell=True
        )
        return result.returncode == 0
    except (FileNotFoundError, subprocess.TimeoutExpired):
        return False


@pytest.mark.integration
@pytest.mark.slow
@pytest.mark.skipif(
    not check_openapi_generator_available(),
    reason="openapi-generator-cli not available"
)
class TestOpenAPIEnhancedGeneratorRealE2E:
    """Real end-to-end integration tests using actual openapi-generator-cli"""
    
    @pytest.mark.timeout(300)  # 5 minute timeout
    def test_simple_openapi_to_mcp_generation(self, simple_openapi_spec, integration_config):
        """
        Test the complete flow with a simple OpenAPI spec
        
        This test uses the REAL openapi-generator-cli and validates:
        1. OpenAPI spec â†’ client generation
        2. Client analysis and tool mapping
        3. MCP project generation
        4. Generated code syntax validation
        """
        print("\nðŸš€ Starting OpenAPIEnhancedGenerator E2E Integration Test")
        print("=" * 60)
        
        generator = OpenAPIEnhancedGenerator()
        print("âœ… Generator initialized")
        
        with tempfile.TemporaryDirectory() as temp_dir:
            print(f"ðŸ“ Using temporary directory: {temp_dir}")
            project_path = Path(temp_dir) / integration_config.project_name
            print(f"ðŸ“ Project path: {project_path}")
            
            # Write the OpenAPI spec to a temporary file
            print("ðŸ“ Writing OpenAPI spec to temporary file...")
            spec_file = Path(temp_dir) / "openapi.json"
            with open(spec_file, 'w') as f:
                json.dump(simple_openapi_spec, f, indent=2)
            print(f"âœ… OpenAPI spec written to: {spec_file}")
            
            # Update config to use the spec file
            print("âš™ï¸ Creating test configuration...")
            test_config = MCPProjectConfig(
                project_name=integration_config.project_name,
                service_name=integration_config.service_name,
                description=integration_config.description,
                author=integration_config.author,
                version=integration_config.version,
                python_version=integration_config.python_version,
                test_framework=integration_config.test_framework,
                include_docker=integration_config.include_docker,
                include_ci=integration_config.include_ci,
                openapi_spec=str(spec_file)  # Provide the spec file path
            )
            print("âœ… Configuration created")
            
            # Generate the complete project
            print("\nðŸ”§ Starting project generation...")
            print("â³ This may take a few minutes with openapi-generator-cli...")
            
            import time
            start_time = time.time()
            
            try:
                result = generator.generate(
                    project_path=project_path,
                    config=test_config,
                    openapi_data=simple_openapi_spec,
                    include_examples=False,
                    max_tools=5
                )
                
                end_time = time.time()
                duration = end_time - start_time
                print(f"\nâ±ï¸ Generation completed in {duration:.2f} seconds")
                
            except Exception as e:
                end_time = time.time()
                duration = end_time - start_time
                print(f"\nâŒ Generation failed after {duration:.2f} seconds")
                print(f"ðŸ’¥ Exception: {type(e).__name__}: {e}")
                raise
            
            # Basic validation - should not crash
            assert isinstance(result, GenerationResult)
            
            # If successful, validate structure
            if result.success:
                self._validate_basic_project_structure(project_path, test_config)
                self._validate_generated_code_syntax(project_path)
            else:
                # Log errors for debugging but don't fail immediately
                print(f"Generation errors: {result.errors}")
                print(f"Generation warnings: {result.warnings}")
                print(f"Files created: {len(result.files_created)}")
                
                # Check if it's a known issue we can work around
                if any("openapi-generator" in error.lower() for error in result.errors):
                    pytest.skip("OpenAPI generator issue - needs investigation")
                else:
                    # Assert after logging details
                    assert result.success, f"Generation failed: {result.errors}"
    
    def test_petstore_openapi_to_mcp_generation(self, petstore_openapi_spec, integration_config):
        """
        Test with the more complex Pet Store OpenAPI spec
        """
        generator = OpenAPIEnhancedGenerator()
        
        with tempfile.TemporaryDirectory() as temp_dir:
            project_path = Path(temp_dir) / "petstore-mcp-server"
            
            # Write the OpenAPI spec to a temporary file
            spec_file = Path(temp_dir) / "petstore-openapi.json"
            with open(spec_file, 'w') as f:
                json.dump(petstore_openapi_spec, f, indent=2)
            
            # Update config for petstore
            petstore_config = MCPProjectConfig(
                project_name="petstore-mcp-server",
                service_name="petstore",
                description="Pet Store MCP Server - Integration Test",
                author=integration_config.author,
                version=integration_config.version,
                python_version=integration_config.python_version,
                test_framework=integration_config.test_framework,
                include_docker=False,
                include_ci=False,
                openapi_spec=str(spec_file)
            )
            
            # Generate the complete project
            result = generator.generate(
                project_path=project_path,
                config=petstore_config,
                openapi_data=petstore_openapi_spec,
                include_examples=True,
                max_tools=10
            )
            
            # Basic validation
            assert isinstance(result, GenerationResult)
            
            if result.success:
                self._validate_enhanced_project_structure(project_path, petstore_config)
                self._validate_generated_code_syntax(project_path)
                self._validate_petstore_specific_content(project_path, petstore_config)
            else:
                # Log for debugging
                print(f"Petstore generation errors: {result.errors}")
                print(f"Files created: {len(result.files_created)}")
                
                # Check for known issues
                if any("timeout" in error.lower() for error in result.errors):
                    pytest.skip("Generation timeout - may need more time on this system")
                elif any("permission" in error.lower() for error in result.errors):
                    pytest.skip("Permission issue - may be system-specific")
                else:
                    assert result.success, f"Petstore generation failed: {result.errors}"
    
    def _validate_basic_project_structure(self, project_path: Path, config: MCPProjectConfig):
        """Validate basic project structure exists"""
        # The actual service directory uses the project name, not service name
        # This is because MCPProjectConfig.get_mcp_package_path() uses project_name
        service_dir_name = f"mcp_{config.project_name.replace('-', '_')}"
        
        essential_files = [
            f"src/{service_dir_name}/__init__.py",
            f"src/{service_dir_name}/server.py", 
            f"src/{service_dir_name}/tools.py",
            "requirements.txt",
            "pyproject.toml",
            "README.md"
        ]
        
        print(f"ðŸ” Validating project structure with service directory: {service_dir_name}")
        
        for file_path in essential_files:
            full_path = project_path / file_path
            print(f"  Checking: {file_path} -> {'âœ…' if full_path.exists() else 'âŒ'}")
            assert full_path.exists(), f"Missing essential file: {file_path}"
            assert full_path.is_file(), f"Path is not a file: {file_path}"
        
        print("âœ… All essential files found!")
    
    def _validate_enhanced_project_structure(self, project_path: Path, config: MCPProjectConfig):
        """Validate enhanced project structure with generated client"""
        # Check standard MCP project files
        self._validate_basic_project_structure(project_path, config)
        
        # Check that we have Python files (should include generated client)
        python_files = list(project_path.rglob("*.py"))
        assert len(python_files) >= 5, f"Expected at least 5 Python files, found {len(python_files)}"
        
        # Check that tools.py has reasonable content
        service_dir_name = f"mcp_{config.project_name.replace('-', '_')}"
        tools_file = project_path / f"src/{service_dir_name}/tools.py"
        if tools_file.exists():
            tools_content = tools_file.read_text()
            assert len(tools_content) > 100, "Tools file seems too short"
    
    def _validate_generated_code_syntax(self, project_path: Path):
        """Validate all generated Python files have valid syntax"""
        import ast
        
        python_files = list(project_path.rglob("*.py"))
        syntax_errors = []
        
        for python_file in python_files:
            try:
                content = python_file.read_text(encoding='utf-8')
                ast.parse(content)
            except SyntaxError as e:
                syntax_errors.append(f"Syntax error in {python_file}: {e}")
            except UnicodeDecodeError as e:
                syntax_errors.append(f"Encoding error in {python_file}: {e}")
        
        if syntax_errors:
            pytest.fail(f"Found syntax errors:\n" + "\n".join(syntax_errors))
    
    def _validate_petstore_specific_content(self, project_path: Path, config: MCPProjectConfig):
        """Validate Pet Store specific content was generated"""
        service_dir_name = f"mcp_{config.project_name.replace('-', '_')}"
        tools_file = project_path / f"src/{service_dir_name}/tools.py"
        if tools_file.exists():
            tools_content = tools_file.read_text()
            
            # Should reference pet-related operations
            pet_terms = ["pet", "Pet", "list", "create", "get"]
            found_terms = [term for term in pet_terms if term in tools_content]
            
            assert len(found_terms) >= 2, f"Expected pet-related terms in tools.py, found: {found_terms}"


@pytest.mark.integration
@pytest.mark.skipif(
    not check_openapi_generator_available(),
    reason="openapi-generator-cli not available"
)
class TestOpenAPIEnhancedGeneratorErrorHandling:
    """Test error handling with real openapi-generator-cli"""
    
    def test_invalid_openapi_spec_handling(self, integration_config):
        """Test handling of invalid OpenAPI specifications"""
        generator = OpenAPIEnhancedGenerator()
        
        invalid_spec = {
            "openapi": "3.0.0",
            # Missing required info section
            "paths": {}
        }
        
        with tempfile.TemporaryDirectory() as temp_dir:
            project_path = Path(temp_dir) / integration_config.project_name
            
            result = generator.generate(
                project_path=project_path,
                config=integration_config,
                openapi_data=invalid_spec
            )
            
            # Should handle gracefully - either succeed with warnings or fail gracefully
            assert isinstance(result, GenerationResult)
            assert isinstance(result.success, bool)
            assert isinstance(result.errors, list)
            
            # If it fails, should have meaningful error messages
            if not result.success:
                assert len(result.errors) > 0
                # Should not crash with unhandled exceptions
                assert all(isinstance(error, str) for error in result.errors)
    
    def test_empty_openapi_spec_handling(self, integration_config):
        """Test handling of empty OpenAPI specifications"""
        generator = OpenAPIEnhancedGenerator()
        
        empty_spec = {
            "openapi": "3.0.0",
            "info": {"title": "Empty API", "version": "1.0.0"},
            "paths": {}
        }
        
        with tempfile.TemporaryDirectory() as temp_dir:
            project_path = Path(temp_dir) / integration_config.project_name
            
            result = generator.generate(
                project_path=project_path,
                config=integration_config,
                openapi_data=empty_spec
            )
            
            # Should handle empty specs gracefully
            assert isinstance(result, GenerationResult)
            
            # Even if empty, should create basic project structure
            if result.success:
                basic_files = [
                    f"src/mcp_{integration_config.service_name}/__init__.py",
                    "requirements.txt",
                    "README.md"
                ]
                
                for file_path in basic_files:
                    full_path = project_path / file_path
                    assert full_path.exists(), f"Missing basic file: {file_path}"


@pytest.mark.integration
@pytest.mark.slow
@pytest.mark.skipif(
    not check_openapi_generator_available(),
    reason="openapi-generator-cli not available"
)
class TestOpenAPIEnhancedGeneratorPerformance:
    """Performance tests with real openapi-generator-cli"""
    
    def test_generation_performance_reasonable_time(self, simple_openapi_spec, integration_config):
        """Test that generation completes within reasonable time"""
        import time
        
        generator = OpenAPIEnhancedGenerator()
        
        with tempfile.TemporaryDirectory() as temp_dir:
            project_path = Path(temp_dir) / integration_config.project_name
            
            # Write spec file
            spec_file = Path(temp_dir) / "simple-openapi.json"
            with open(spec_file, 'w') as f:
                json.dump(simple_openapi_spec, f, indent=2)
            
            test_config = MCPProjectConfig(
                project_name=integration_config.project_name,
                service_name=integration_config.service_name,
                description=integration_config.description,
                author=integration_config.author,
                openapi_spec=str(spec_file)
            )
            
            start_time = time.time()
            result = generator.generate(
                project_path=project_path,
                config=test_config,
                openapi_data=simple_openapi_spec,
                max_tools=5
            )
            end_time = time.time()
            
            generation_time = end_time - start_time
            
            # Log timing information
            print(f"Generation completed in {generation_time:.2f} seconds")
            print(f"Success: {result.success}")
            print(f"Files created: {len(result.files_created)}")
            
            # Should complete within reasonable time (2 minutes for simple spec)
            assert generation_time < 120.0, f"Generation took too long: {generation_time:.2f} seconds"
            
            # Should create at least some files even if there are issues
            assert len(result.files_created) > 0, "No files were created" 